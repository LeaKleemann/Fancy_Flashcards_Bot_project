{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.de import German\n",
    "import spacy\n",
    "import json\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(question):\n",
    "    doc = nlp(question)\n",
    "    return_list=[]\n",
    "    for token in doc:\n",
    "        if token.pos_ != \"PUNCT\":\n",
    "            if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                text=token.text\n",
    "                return_list.append(text.lower())\n",
    "            else:\n",
    "                return_list.append(token.lemma_.lower())\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions=[]\n",
    "fancy_flashcards = {}\n",
    "path='./wirtschaftsinformatik'\n",
    "for file in os.listdir(path):\n",
    "    file_path=path+'/'+file\n",
    "    file_list=file.split('.')\n",
    "    if file_list[-1]=='json':\n",
    "        with open(file_path, encoding='utf-8') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            temp_dict = {}\n",
    "            decks=list(data['decks'].keys())\n",
    "            cards=data['decks'][decks[0]]['cards']\n",
    "            for index in cards.keys():\n",
    "                temp_dict[cards[index]['q']]=cards[index]['a']\n",
    "                all_questions.append(cards[index]['q'])\n",
    "            fancy_flashcards[file_list[0]]=temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\buche\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
    "X = vectorizer.fit(all_questions)\n",
    "features = X.transform(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Was ist Business Intelligence?\"\n",
    "new_features = X.transform([question])\n",
    "cosine_sim = cosine_similarity(features, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was versteht man unter Business Intelligence (BI) (Lackes/ Siepermann)? [0.53983126]\n"
     ]
    }
   ],
   "source": [
    "max_idx=cosine_sim.argmax()\n",
    "print(all_questions[max_idx], cosine_sim[max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
